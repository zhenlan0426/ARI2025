{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55160d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.642 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c79415ec721437a8f3cc0e0c4592bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "# from transformers.models.gemma3.modeling_gemma3 import Gemma3TextScaledWordEmbedding\n",
    "from functions import *\n",
    "# model, tokenizer = FastModel.from_pretrained(\n",
    "#     model_name = \"unsloth/gemma-3-4b-pt-unsloth-bnb-4bit\",\n",
    "#     max_seq_length = 8192, # Choose any for long context!\n",
    "#     load_in_4bit = True,\n",
    "#     resize_model_vocab=24,\n",
    "# )\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    # model_name=\"unsloth/gemma-3-12b-pt\",\n",
    "    # model_name=\"unsloth/gemma-3-4b-pt\",\n",
    "    max_seq_length = 8192, # Choose any for long context!\n",
    "    load_in_4bit = True,\n",
    "    resize_model_vocab=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a787dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gemma3\n",
    "# model.config.image_token_index = 16 # new image token\n",
    "# model.language_model.lm_head.weight.requires_grad_(True);\n",
    "# # # model.language_model.lm_head.load_state_dict(torch.load(\"/home/zhenlan/Desktop/Projects/ARC2/Model/gemma24.pth\"))\n",
    "# model.language_model.lm_head.load_state_dict(torch.load(\"../../Model/lm_heads_weights_VLM2.pth\"))\n",
    "# model = PeftModel.from_pretrained(model, \"../../Model/merged_model_VLM2\", is_trainable=False)\n",
    "# model.eval()\n",
    "# model.language_model.model.gradient_checkpointing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbfc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e425388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_head.load_state_dict(torch.load(\"../../Model/qwen16.pth\"))\n",
    "model.model.embed_tokens.load_state_dict(torch.load(\"../../Model/qwen16.pth\"))\n",
    "model = PeftModel.from_pretrained(model, \"../../Model/merged_model_qwen\", is_trainable=True)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007f3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_path = '/home/zhenlan/Desktop/Projects/ARC2/Data/ARC-AGI-2-main/combined_data.json'\n",
    "with open(output_path, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02368fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_idx 1986 end_idx 2856\n"
     ]
    }
   ],
   "source": [
    "inputs_f = next(iter(data_gen(data, IsTrain=False, max_length=8192, autoregressive=True, NeedPosition=False, tokenize_func=tokenize_causal, IsDecode=False)))\n",
    "inputs_t = next(iter(data_gen(data, IsTrain=False, max_length=8192, autoregressive=True, NeedPosition=False, tokenize_func=tokenize_causal, IsDecode=True)))\n",
    "start_idx = len(inputs_t['input_tokens'][0]) - 1\n",
    "end_idx = len(inputs_f['input_tokens'][0]) - 2\n",
    "print(\"start_idx\", start_idx, \"end_idx\", end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d630705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_f, y_f = next(iter(data_gen_VLM(data, False, tokenizer, 3, False)))\n",
    "# inputs_t, y_t = next(iter(data_gen_VLM(data, False, tokenizer, 3, True)))\n",
    "# start_idx = len(inputs_t['input_ids'][0]) - 1\n",
    "# end_idx = len(inputs_f['input_ids'][0]) - 2\n",
    "# start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33a45526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit1 and logit2 give different results, suggesting something is sequence length dependent.\n",
    "# tested mannual casual mask, still see the difference. So not caused by mask.\n",
    "# model.eval();\n",
    "# with torch.no_grad():\n",
    "#     with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#         outputs_full = model(**inputs_f)\n",
    "#         logits1 = outputs_full.logits[0, :start_idx+1]\n",
    "\n",
    "# # shorten inputs\n",
    "# inputs_f['input_ids'] = inputs_f['input_ids'][:, :start_idx+1]\n",
    "# # inputs_f['attention_mask'] = inputs_f['attention_mask'][:, :, :start_idx+1, :start_idx+1]\n",
    "# inputs_f['attention_mask'] = inputs_f['attention_mask'][:, :start_idx+1]\n",
    "# inputs_f['token_type_ids'] = inputs_f['token_type_ids'][:, :start_idx+1]\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#         outputs_full = model(**inputs_f)\n",
    "#         logits2 = outputs_full.logits\n",
    "# torch.sum(logits1.argmax(-1) == logits2.argmax(-1))/logits1.shape[0]\n",
    "# torch.mean(torch.abs(logits1 - logits2)) # original mask, no peft\n",
    "# torch.mean(torch.abs(logits1 - logits2)) # casual mask\n",
    "# torch.mean(torch.abs(logits1 - logits2)) # original mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c735e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model);\n",
    "with torch.no_grad():\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        outputs_full = model(inputs_f['input_tokens'])\n",
    "        logits1 = outputs_full.logits[0, start_idx: end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5123de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import HybridCache\n",
    "# past_key_values = HybridCache(model.config.text_config, 1, 5600)\n",
    "# logits2 = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # Initial pass with the input prompt\n",
    "#     with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#         outputs_kv_init = model(**inputs_t, use_cache=True, past_key_values=past_key_values)\n",
    "#         # outputs_kv_init = model(**inputs_t)\n",
    "#         logits2.append(outputs_kv_init.logits[0, -1, :])\n",
    "#         # Store the KV cache from initial pass\n",
    "#         past_key_values = outputs_kv_init.past_key_values\n",
    "\n",
    "#     # Iterate through the continuation tokens\n",
    "#     for i in range(end_idx - start_idx - 1):\n",
    "#         # Prepare input for the next iteration: only the current continuation token\n",
    "#         current_token_id_tensor = inputs_f['input_ids'][:, start_idx + i + 1].unsqueeze(1)\n",
    "\n",
    "#         # Model call with the single next token and past_key_values\n",
    "#         with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#             outputs_kv_step = model(input_ids=current_token_id_tensor, \n",
    "#                                    past_key_values=past_key_values, \n",
    "#                                    use_cache=True,\n",
    "#                                 #    attention_mask=inputs_f['attention_mask'][:, :start_idx + i + 2], # .unsqueeze(0).unsqueeze(0)\n",
    "#                                 #    token_type_ids=inputs_f['token_type_ids'][:, start_idx + i + 1:start_idx + i + 2],\n",
    "#                                    ) # \n",
    "#             # Store the logits from this step - CORRECTION HERE\n",
    "#             logits2.append(outputs_kv_step.logits[0, -1, :])\n",
    "#             # Update KV cache with new values\n",
    "#             past_key_values = outputs_kv_step.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e863900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import StaticCache\n",
    "# model.config.text_config.sliding_window_pattern = 1 # disable sliding window. all layers use static cache now\n",
    "past_key_values = StaticCache(model.config, 1, 2888, device='cuda')\n",
    "# Assume 'model', 'inputs_t', 'inputs_f', 'start_idx', 'end_idx', 'past_key_values'\n",
    "# are already defined and loaded appropriately.\n",
    "# 'model' is a Hugging Face transformer model supporting 'cache_position'.\n",
    "# 'inputs_t' contains the initial prompt tensors (e.g., {'input_ids': tensor, 'attention_mask': tensor})\n",
    "# 'inputs_f' contains the full sequence including continuation tokens.\n",
    "# 'past_key_values' might be None initially or contain a pre-filled cache.\n",
    "\n",
    "logits2 = []\n",
    "current_seq_len = inputs_t['input_tokens'].shape[1] # Keep track of the sequence length processed so far\n",
    "\n",
    "with torch.no_grad():\n",
    "    # --- Initial pass with the input prompt ---\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        outputs_kv_init = model(\n",
    "            inputs_t['input_tokens'], # Only the prompt\n",
    "            use_cache=True,\n",
    "            past_key_values=past_key_values,\n",
    "        )\n",
    "        # Store the logit for the *last* token of the prompt\n",
    "        logits2.append(outputs_kv_init.logits[0, -1, :])\n",
    "        # Store the KV cache from initial pass\n",
    "        past_key_values = outputs_kv_init.past_key_values\n",
    "        # Update the sequence length tracker\n",
    "\n",
    "    # --- Iterate through the continuation tokens ---\n",
    "    num_continuation_tokens = end_idx - start_idx - 1\n",
    "    for i in range(num_continuation_tokens):\n",
    "        # Prepare input for the next iteration: only the current continuation token\n",
    "        # Note: Original code uses inputs_f. Ensure this aligns with your logic.\n",
    "        # Usually, in generation, the input is the *predicted* token from the previous step.\n",
    "        # Assuming inputs_f contains ground truth continuation here for analysis.\n",
    "        current_token_id_tensor = inputs_f['input_tokens'][:, start_idx + i + 1].unsqueeze(1) # Shape: (batch_size, 1)\n",
    "\n",
    "        # The position for this single token is the current total sequence length\n",
    "        # Needs to have shape (batch_size, 1)\n",
    "\n",
    "        # Model call with the single next token and past_key_values\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            outputs_kv_step = model(\n",
    "                input_ids=current_token_id_tensor,\n",
    "                past_key_values=past_key_values,\n",
    "                cache_position=torch.tensor([current_seq_len], device='cuda'),\n",
    "                use_cache=True,\n",
    "            )\n",
    "            # Store the logits for the token we just processed\n",
    "            # Logits shape is (batch_size, 1, vocab_size), so index [0, 0, :] or [0, -1, :]\n",
    "            logits2.append(outputs_kv_step.logits[0, -1, :]) # Index 0 as seq_len is 1\n",
    "            # Update KV cache with new values\n",
    "            past_key_values = outputs_kv_step.past_key_values\n",
    "            # Increment the sequence length tracker\n",
    "            current_seq_len += 1\n",
    "\n",
    "logits2 = torch.stack(logits2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0312,  0.0156,  0.0312,  0.0312,  0.0000, -0.0234,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0156,\n",
       "           0.0000,  0.0000]]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roll back to first token, simulate dfs backtrack. cache position is needed to \"un-do\" (backtrack) changes made to past_key_values in deeper dfs\n",
    "current_token_id_tensor = inputs_f['input_tokens'][:, start_idx + 0 + 1].unsqueeze(1) # Shape: (batch_size, 1)\n",
    "\n",
    "# The position for this single token is the current total sequence length\n",
    "# Needs to have shape (batch_size, 1)\n",
    "\n",
    "# Model call with the single next token and past_key_values\n",
    "with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "    outputs_kv_step = model(\n",
    "        input_ids=current_token_id_tensor,\n",
    "        past_key_values=past_key_values,\n",
    "        cache_position=torch.tensor([inputs_t['input_tokens'].shape[1]], device='cuda'),\n",
    "        use_cache=True,\n",
    "    )\n",
    "logits2[1] - outputs_kv_step.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9447787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0093, device='cuda:0', dtype=torch.bfloat16, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(logits2[1] - outputs_kv_step.logits).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1191f393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0142, 0.0198, 0.0198, 0.0178, 0.0198, 0.0273, 0.0256, 0.0535, 0.0205,\n",
       "        0.0281, 0.0210, 0.0295, 0.0154, 0.0166, 0.0173, 0.0181, 0.0142, 0.0300,\n",
       "        0.0238, 0.0239, 0.0349, 0.0308, 0.0337, 0.0239, 0.0430, 0.0347, 0.0227,\n",
       "        0.0278, 0.0244, 0.0194, 0.0337, 0.0303, 0.0261, 0.0168, 0.0206, 0.0170,\n",
       "        0.0248, 0.0222, 0.0261, 0.0172, 0.0131, 0.0229, 0.0239, 0.0312, 0.0278,\n",
       "        0.0205, 0.0090, 0.0146, 0.0162, 0.0195, 0.0171, 0.0337, 0.0186, 0.0137,\n",
       "        0.0162, 0.0225, 0.0198, 0.0347, 0.0306, 0.0332, 0.0349, 0.0247, 0.0142,\n",
       "        0.0229, 0.0171, 0.0176, 0.0247, 0.0220, 0.0168, 0.0181, 0.0195, 0.0193,\n",
       "        0.0193, 0.0264, 0.0120, 0.0273, 0.0181, 0.0216, 0.0157, 0.0242, 0.0156,\n",
       "        0.0430, 0.0233, 0.0098, 0.0123, 0.0269, 0.0153, 0.0381, 0.0233, 0.0405,\n",
       "        0.0483, 0.0122, 0.0295, 0.0225, 0.0339, 0.0176, 0.0256, 0.0200, 0.0332,\n",
       "        0.0205, 0.0259, 0.0222, 0.0232, 0.0173, 0.0332, 0.0288, 0.0129, 0.0159,\n",
       "        0.0208, 0.0256, 0.0302, 0.0269, 0.0277, 0.0137, 0.0173, 0.0129, 0.0166,\n",
       "        0.0359, 0.0161, 0.0168, 0.0454, 0.0170, 0.0258, 0.0200, 0.0210, 0.0236,\n",
       "        0.0332, 0.0204, 0.0306, 0.0264, 0.0208, 0.0166, 0.0233, 0.0134, 0.0420,\n",
       "        0.0303, 0.0203, 0.0111, 0.0217, 0.0139, 0.0219, 0.0391, 0.0212, 0.0217,\n",
       "        0.0210, 0.0225, 0.0186, 0.0239, 0.0305, 0.0269, 0.0378, 0.0160, 0.0116,\n",
       "        0.0151, 0.0247, 0.0205, 0.0232, 0.0342, 0.0298, 0.0206, 0.0170, 0.0239,\n",
       "        0.0247, 0.0183, 0.0322, 0.0236, 0.0251, 0.0125, 0.0193, 0.0115, 0.0145,\n",
       "        0.0288, 0.0223, 0.0156, 0.0264, 0.0105, 0.0239, 0.0269, 0.0203, 0.0403,\n",
       "        0.0371, 0.0396, 0.0293, 0.0156, 0.0154, 0.0165, 0.0273, 0.0294, 0.0173,\n",
       "        0.0249, 0.0168, 0.0293, 0.0178, 0.0272, 0.0195, 0.0222, 0.0138, 0.0123,\n",
       "        0.0215, 0.0222, 0.0308, 0.0396, 0.0344, 0.0203, 0.0105, 0.0283, 0.0226,\n",
       "        0.0258, 0.0312, 0.0312, 0.0466, 0.0457, 0.0128, 0.0176, 0.0378, 0.0233,\n",
       "        0.0239, 0.0361, 0.0272, 0.0254, 0.0229, 0.0225, 0.0236, 0.0361, 0.0199,\n",
       "        0.0361, 0.0269, 0.0234, 0.0208, 0.0164, 0.0284, 0.0238, 0.0260, 0.0151,\n",
       "        0.0186, 0.0212, 0.0198, 0.0142, 0.0209, 0.0220, 0.0269, 0.0149, 0.0172,\n",
       "        0.0281, 0.0303, 0.0156, 0.0125, 0.0240, 0.0267, 0.0283, 0.0337, 0.0203,\n",
       "        0.0200, 0.0253, 0.0275, 0.0396, 0.0175, 0.0214, 0.0222, 0.0183, 0.0122,\n",
       "        0.0270, 0.0276, 0.0182, 0.0249, 0.0273, 0.0249, 0.0396, 0.0177, 0.0488,\n",
       "        0.0464, 0.0344, 0.0277, 0.0181, 0.0220, 0.0266, 0.0288, 0.0215, 0.0173,\n",
       "        0.0205, 0.0317, 0.0186, 0.0253, 0.0312, 0.0249, 0.0325, 0.0137, 0.0117,\n",
       "        0.0203, 0.0227, 0.0250, 0.0205, 0.0352, 0.0175, 0.0254, 0.0146, 0.0356,\n",
       "        0.0227, 0.0291, 0.0312, 0.0332, 0.0400, 0.0342, 0.0188, 0.0159, 0.0250,\n",
       "        0.0347, 0.0144, 0.0244, 0.0256, 0.0183, 0.0259, 0.0145, 0.0229, 0.0210,\n",
       "        0.0232, 0.0178, 0.0149, 0.0188, 0.0262, 0.0391, 0.0190, 0.0276, 0.0168,\n",
       "        0.0269, 0.0312, 0.0283, 0.0141, 0.0166, 0.0233, 0.0405, 0.0217, 0.0255,\n",
       "        0.0081, 0.0135, 0.0212, 0.0398, 0.0349, 0.0183, 0.0352, 0.0283, 0.0229,\n",
       "        0.0195, 0.0188, 0.0247, 0.0430, 0.0261, 0.0120, 0.0159, 0.0168, 0.0175,\n",
       "        0.0260, 0.0205, 0.0205, 0.0127, 0.0223, 0.0204, 0.0217, 0.0288, 0.0215,\n",
       "        0.0427, 0.0469, 0.0261, 0.0122, 0.0386, 0.0231, 0.0315, 0.0393, 0.0227,\n",
       "        0.0254, 0.0186, 0.0171, 0.0200, 0.0242, 0.0295, 0.0295, 0.0283, 0.0259,\n",
       "        0.0139, 0.0291, 0.0225, 0.0239, 0.0330, 0.0168, 0.0156, 0.0181, 0.0211,\n",
       "        0.0277, 0.0232, 0.0308, 0.0347, 0.0256, 0.0234, 0.0220, 0.0388, 0.0178,\n",
       "        0.0413, 0.0311, 0.0262, 0.0449, 0.0166, 0.0320, 0.0239, 0.0361, 0.0143,\n",
       "        0.0391, 0.0210, 0.0217, 0.0342, 0.0200, 0.0161, 0.0327, 0.0171, 0.0132,\n",
       "        0.0107, 0.0264, 0.0225, 0.0286, 0.0388, 0.0234, 0.0518, 0.0256, 0.0190,\n",
       "        0.0128, 0.0227, 0.0143, 0.0228, 0.0310, 0.0190, 0.0249, 0.0223, 0.0210,\n",
       "        0.0259, 0.0198, 0.0278, 0.0211, 0.0259, 0.0225, 0.0189, 0.0216, 0.0295,\n",
       "        0.0366, 0.0322, 0.0193, 0.0300, 0.0156, 0.0311, 0.0264, 0.0366, 0.0435,\n",
       "        0.0256, 0.0197, 0.0199, 0.0205, 0.0181, 0.0238, 0.0127, 0.0354, 0.0245,\n",
       "        0.0269, 0.0229, 0.0308, 0.0149, 0.0170, 0.0282, 0.0197, 0.0242, 0.0237,\n",
       "        0.0132, 0.0234, 0.0249, 0.0322, 0.0271, 0.0254, 0.0205, 0.0176, 0.0359,\n",
       "        0.0381, 0.0566, 0.0249, 0.0297, 0.0214, 0.0204, 0.0193, 0.0146, 0.0291,\n",
       "        0.0162, 0.0229, 0.0173, 0.0232, 0.0303, 0.0142, 0.0222, 0.0228, 0.0300,\n",
       "        0.0352, 0.0217, 0.0161, 0.0190, 0.0149, 0.0510, 0.0234, 0.0238, 0.0271,\n",
       "        0.0195, 0.0288, 0.0161, 0.0186, 0.0437, 0.0186, 0.0452, 0.0186, 0.0262,\n",
       "        0.0192, 0.0162, 0.0187, 0.0251, 0.0236, 0.0182, 0.0225, 0.0273, 0.0193,\n",
       "        0.0181, 0.0205, 0.0278, 0.0315, 0.0215, 0.0239, 0.0142, 0.0205, 0.0304,\n",
       "        0.0269, 0.0304, 0.0322, 0.0303, 0.0144, 0.0291, 0.0405, 0.0295, 0.0137,\n",
       "        0.0245, 0.0095, 0.0239, 0.0146, 0.0156, 0.0220, 0.0111, 0.0259, 0.0161,\n",
       "        0.0251, 0.0264, 0.0103, 0.0079, 0.0366, 0.0229, 0.0347, 0.0212, 0.0142,\n",
       "        0.0217, 0.0258, 0.0376, 0.0283, 0.0142, 0.0210, 0.0139, 0.0256, 0.0359,\n",
       "        0.0349, 0.0277, 0.0248, 0.0203, 0.0150, 0.0284, 0.0339, 0.0359, 0.0286,\n",
       "        0.0150, 0.0271, 0.0222, 0.0256, 0.0254, 0.0154, 0.0417, 0.0267, 0.0149,\n",
       "        0.0247, 0.0195, 0.0205, 0.0137, 0.0188, 0.0190, 0.0425, 0.0259, 0.0266,\n",
       "        0.0210, 0.0249, 0.0320, 0.0210, 0.0310, 0.0198, 0.0503, 0.0265, 0.0308,\n",
       "        0.0192, 0.0229, 0.0342, 0.0366, 0.0356, 0.0294, 0.0430, 0.0079, 0.0178,\n",
       "        0.0232, 0.0132, 0.0332, 0.0222, 0.0253, 0.0303, 0.0242, 0.0176, 0.0244,\n",
       "        0.0212, 0.0189, 0.0295, 0.0225, 0.0215, 0.0151, 0.0354, 0.0356, 0.0225,\n",
       "        0.0243, 0.0322, 0.0176, 0.0125, 0.0249, 0.0256, 0.0292, 0.0361, 0.0217,\n",
       "        0.0347, 0.0283, 0.0269, 0.0327, 0.0250, 0.0410, 0.0320, 0.0232, 0.0227,\n",
       "        0.0291, 0.0312, 0.0187, 0.0403, 0.0225, 0.0156, 0.0142, 0.0305, 0.0371,\n",
       "        0.0342, 0.0337, 0.0430, 0.0182, 0.0239, 0.0197, 0.0137, 0.0222, 0.0304,\n",
       "        0.0303, 0.0317, 0.0248, 0.0298, 0.0195, 0.0176, 0.0288, 0.0327, 0.0435,\n",
       "        0.0264, 0.0359, 0.0203, 0.0250, 0.0135, 0.0209, 0.0405, 0.0172, 0.0232,\n",
       "        0.0117, 0.0177, 0.0205, 0.0216, 0.0179, 0.0454, 0.0205, 0.0289, 0.0289,\n",
       "        0.0198, 0.0165, 0.0405, 0.0284, 0.0330, 0.0255, 0.0254, 0.0188, 0.0366,\n",
       "        0.0156, 0.0227, 0.0430, 0.0520, 0.0176, 0.0178, 0.0217, 0.0291, 0.0354,\n",
       "        0.0248, 0.0247, 0.0320, 0.0181, 0.0251, 0.0369, 0.0239, 0.0220, 0.0315,\n",
       "        0.0413, 0.0159, 0.0237, 0.0208, 0.0186, 0.0105, 0.0211, 0.0298, 0.0206,\n",
       "        0.0273, 0.0283, 0.0171, 0.0160, 0.0131, 0.0205, 0.0247, 0.0164, 0.0164,\n",
       "        0.0110, 0.0232, 0.0132, 0.0156, 0.0095, 0.0208, 0.0254, 0.0146, 0.0247,\n",
       "        0.0249, 0.0422, 0.0332, 0.0245, 0.0149, 0.0193, 0.0334, 0.0203, 0.0188,\n",
       "        0.0320, 0.0444, 0.0276, 0.0208, 0.0239, 0.0261, 0.0149, 0.0170, 0.0398,\n",
       "        0.0400, 0.0232, 0.0244, 0.0190, 0.0151, 0.0242, 0.0227, 0.0205, 0.0242,\n",
       "        0.0361, 0.0247, 0.0186, 0.0256, 0.0605, 0.0176, 0.0315, 0.0304, 0.0256,\n",
       "        0.0247, 0.0170, 0.0327, 0.0160, 0.0199, 0.0269, 0.0298, 0.0294, 0.0283,\n",
       "        0.0208, 0.0212, 0.0243, 0.0211, 0.0183, 0.0195, 0.0229, 0.0214, 0.0269,\n",
       "        0.0254, 0.0283, 0.0242, 0.0220, 0.0334, 0.0134, 0.0269, 0.0256, 0.0190,\n",
       "        0.0679, 0.0288, 0.0186, 0.0498, 0.0186, 0.0266, 0.0190, 0.0334, 0.0168,\n",
       "        0.0234, 0.0127, 0.0249, 0.0308, 0.0260, 0.0378, 0.0303, 0.0171, 0.0220,\n",
       "        0.0146, 0.0156, 0.0322, 0.0233, 0.0312, 0.0215, 0.0200, 0.0156, 0.0276,\n",
       "        0.0664, 0.0330, 0.0391, 0.0342, 0.0281, 0.0270, 0.0229, 0.0408, 0.0129,\n",
       "        0.0352, 0.0430, 0.0194, 0.0325, 0.0315, 0.0544, 0.0540, 0.0281, 0.0209,\n",
       "        0.0288, 0.0422, 0.0210, 0.0256, 0.0359, 0.0408, 0.0177, 0.0304, 0.0248,\n",
       "        0.0205, 0.0347, 0.0261, 0.0312, 0.0430, 0.0334], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(logits1 - logits2),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe67f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemma3\n",
    "# import torch\n",
    "# from transformers import HybridCache\n",
    "# # model.config.text_config.sliding_window_pattern = 1 # disable sliding window. all layers use static cache now\n",
    "# past_key_values = HybridCache(model.config.text_config, 1, 5600)\n",
    "# # Assume 'model', 'inputs_t', 'inputs_f', 'start_idx', 'end_idx', 'past_key_values'\n",
    "# # are already defined and loaded appropriately.\n",
    "# # 'model' is a Hugging Face transformer model supporting 'cache_position'.\n",
    "# # 'inputs_t' contains the initial prompt tensors (e.g., {'input_ids': tensor, 'attention_mask': tensor})\n",
    "# # 'inputs_f' contains the full sequence including continuation tokens.\n",
    "# # 'past_key_values' might be None initially or contain a pre-filled cache.\n",
    "\n",
    "# logits2 = []\n",
    "# current_seq_len = 0 # Keep track of the sequence length processed so far\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # --- Initial pass with the input prompt ---\n",
    "#     with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#         outputs_kv_init = model(\n",
    "#             **inputs_t,\n",
    "#             use_cache=True,\n",
    "#             past_key_values=past_key_values,\n",
    "#         )\n",
    "#         # Store the logit for the *last* token of the prompt\n",
    "#         logits2.append(outputs_kv_init.logits[0, -1, :])\n",
    "#         # Store the KV cache from initial pass\n",
    "#         past_key_values = outputs_kv_init.past_key_values\n",
    "#         # Update the sequence length tracker\n",
    "#         current_seq_len = len(inputs_t['input_ids'][0]) # Assuming batch size of 1\n",
    "\n",
    "#     # --- Iterate through the continuation tokens ---\n",
    "#     num_continuation_tokens = end_idx - start_idx - 1\n",
    "#     for i in range(num_continuation_tokens):\n",
    "#         # Prepare input for the next iteration: only the current continuation token\n",
    "#         # Note: Original code uses inputs_f. Ensure this aligns with your logic.\n",
    "#         # Usually, in generation, the input is the *predicted* token from the previous step.\n",
    "#         # Assuming inputs_f contains ground truth continuation here for analysis.\n",
    "#         current_token_id_tensor = inputs_f['input_ids'][:, start_idx + i + 1].unsqueeze(1) # Shape: (batch_size, 1)\n",
    "\n",
    "#         # The position for this single token is the current total sequence length\n",
    "#         # Needs to have shape (batch_size, 1)\n",
    "#         current_cache_position = torch.tensor([current_seq_len], device=current_token_id_tensor.device)\n",
    "\n",
    "#         # Model call with the single next token and past_key_values\n",
    "#         with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "#             outputs_kv_step = model(\n",
    "#                 input_ids=current_token_id_tensor,\n",
    "#                 past_key_values=past_key_values,\n",
    "#                 use_cache=True,\n",
    "#                 cache_position=current_cache_position # ADDED\n",
    "#             )\n",
    "#             # Store the logits for the token we just processed\n",
    "#             # Logits shape is (batch_size, 1, vocab_size), so index [0, 0, :] or [0, -1, :]\n",
    "#             logits2.append(outputs_kv_step.logits[0, -1, :]) # Index 0 as seq_len is 1\n",
    "#             # Update KV cache with new values\n",
    "#             past_key_values = outputs_kv_step.past_key_values\n",
    "#             # Increment the sequence length tracker\n",
    "#             current_seq_len += 1\n",
    "\n",
    "# logits2 = torch.stack(logits2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd94d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1f5f0d0",
   "metadata": {},
   "source": [
    "Text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52cbb74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma3ForConditionalGeneration(\n",
       "      (vision_tower): SiglipVisionModel(\n",
       "        (vision_model): SiglipVisionTransformer(\n",
       "          (embeddings): SiglipVisionEmbeddings(\n",
       "            (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "            (position_embedding): Embedding(4096, 1152)\n",
       "          )\n",
       "          (encoder): SiglipEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-26): 27 x SiglipEncoderLayer(\n",
       "                (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (self_attn): SiglipAttention(\n",
       "                  (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): SiglipMLP(\n",
       "                  (activation_fn): PytorchGELUTanh()\n",
       "                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (multi_modal_projector): Gemma3MultiModalProjector(\n",
       "        (mm_soft_emb_norm): Gemma3RMSNorm((1152,), eps=1e-06)\n",
       "        (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "      )\n",
       "      (language_model): Gemma3ForCausalLM(\n",
       "        (model): Gemma3TextModel(\n",
       "          (embed_tokens): Gemma3TextScaledWordEmbedding(24, 2560, padding_idx=0)\n",
       "          (layers): ModuleList(\n",
       "            (0): Gemma3DecoderLayer(\n",
       "              (self_attn): Gemma3Attention(\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Gemma3MLP(\n",
       "                (gate_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=10240, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            )\n",
       "            (1): Gemma3DecoderLayer(\n",
       "              (self_attn): Gemma3Attention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Gemma3MLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=10240, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=10240, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            )\n",
       "            (2): Gemma3DecoderLayer(\n",
       "              (self_attn): Gemma3Attention(\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Gemma3MLP(\n",
       "                (gate_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=10240, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            )\n",
       "            (3): Gemma3DecoderLayer(\n",
       "              (self_attn): Gemma3Attention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Gemma3MLP(\n",
       "                (gate_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=10240, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            )\n",
       "            (4): Gemma3DecoderLayer(\n",
       "              (self_attn): Gemma3Attention(\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2048, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Gemma3MLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=10240, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=10240, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            )\n",
       "            (5): Gemma3DecoderLayer(\n",
       "              (self_attn): Gemma3Attention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Gemma3MLP(\n",
       "                (gate_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=10240, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=10240, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            )\n",
       "            (6-33): 28 x Gemma3DecoderLayer(\n",
       "              (self_attn): Gemma3Attention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=2048, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2048, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2048, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2048, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "                (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Gemma3MLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=2560, out_features=10240, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=2560, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=10240, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=10240, out_features=2560, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=10240, out_features=64, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=64, out_features=2560, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): PytorchGELUTanh()\n",
       "              )\n",
       "              (input_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_attention_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (pre_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "              (post_feedforward_layernorm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "            )\n",
       "          )\n",
       "          (norm): Gemma3RMSNorm((2560,), eps=1e-06)\n",
       "          (rotary_emb): Gemma3RotaryEmbedding()\n",
       "          (rotary_emb_local): Gemma3RotaryEmbedding()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=2560, out_features=24, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e05381d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.base_model.language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51b50b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "with torch.no_grad():\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        outputs_full = model(inputs_f['input_ids'])\n",
    "        logits1 = outputs_full.logits[0, start_idx: end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf28be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Initial pass with the input prompt\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        outputs_kv_init = model(inputs_t['input_ids'], use_cache=True)\n",
    "        logits2.append(outputs_kv_init.logits[0, -1, :])\n",
    "        # Store the KV cache from initial pass\n",
    "        past_key_values = outputs_kv_init.past_key_values\n",
    "\n",
    "    # Iterate through the continuation tokens\n",
    "    for i in range(end_idx - start_idx - 1):\n",
    "        # Prepare input for the next iteration: only the current continuation token\n",
    "        current_token_id_tensor = inputs_f['input_ids'][:, start_idx + i + 1].unsqueeze(1)\n",
    "\n",
    "        # Model call with the single next token and past_key_values\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            outputs_kv_step = model(input_ids=current_token_id_tensor, \n",
    "                                   past_key_values=past_key_values, \n",
    "                                   use_cache=True)\n",
    "            # Store the logits from this step - CORRECTION HERE\n",
    "            logits2.append(outputs_kv_step.logits[0, -1, :])\n",
    "            # Update KV cache with new values\n",
    "            past_key_values = outputs_kv_step.past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d73ed24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits2 = torch.stack(logits2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "412df5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([869, 24]), torch.Size([869, 24]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits2.shape, logits1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75b79b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0625, 2.7812, 3.1406, 3.1094, 3.0781, 3.0625, 3.1250, 3.1719, 3.2812,\n",
       "        3.0625, 2.7969, 2.6406, 2.5625, 2.5312, 2.2812, 2.1250, 2.0625, 2.1875,\n",
       "        2.3906, 2.4062, 2.4062, 2.4062, 2.2969, 2.1406, 2.1094, 2.0625, 1.8359,\n",
       "        1.6562, 1.6641, 1.6641, 1.9219, 3.0625, 3.6094, 4.5312, 4.8438, 4.9375,\n",
       "        4.7188, 4.3438, 2.4688, 4.1562, 3.9062, 3.6406, 2.7656, 2.5312, 2.3125,\n",
       "        2.2344, 1.9766, 1.8984, 1.8594, 1.9219, 2.0938, 1.8828, 1.7422, 1.8906,\n",
       "        1.9766, 1.9531, 1.9688, 1.8828, 1.5859, 1.2109, 1.4844, 1.9062, 2.3906,\n",
       "        2.2812, 2.2656, 2.2656, 2.2812, 2.1562, 2.1094, 2.4531, 2.0000, 1.8438,\n",
       "        1.8594, 1.9922, 1.8984, 1.9531, 1.9531, 1.8047, 1.6797, 1.6562, 1.6016,\n",
       "        1.5547, 1.7578, 1.6641, 1.7500, 1.6094, 1.5156, 1.5625, 1.4844, 1.5078,\n",
       "        1.7031, 2.1250, 2.2656, 2.5625, 2.2188, 1.7969, 1.8125, 1.8750, 2.2031,\n",
       "        2.4062, 2.3125, 2.2031, 2.5781, 2.3125, 2.1094, 2.3438, 2.1094, 2.0781,\n",
       "        1.8438, 1.7109, 1.9453, 1.6953, 1.7891, 1.5859, 1.7656, 1.6406, 1.7031,\n",
       "        1.5391, 1.6484, 1.6406, 1.6094, 2.1250, 2.0000, 2.1250, 2.0781, 2.1094,\n",
       "        2.1562, 2.1562, 2.2812, 2.5469, 2.3125, 2.5000, 2.0000, 2.1250, 2.0625,\n",
       "        2.3438, 2.0156, 2.1875, 2.0469, 2.2812, 1.8750, 1.8906, 1.7188, 1.7734,\n",
       "        1.6172, 1.6719, 1.5391, 1.5078, 1.7578, 1.7812, 1.7656, 2.1719, 1.8438,\n",
       "        2.0625, 2.0625, 2.0469, 1.9688, 1.8516, 2.0938, 1.9766, 1.9219, 1.9062,\n",
       "        2.0156, 2.0000, 1.8906, 1.9531, 2.0000, 2.0781, 1.9141, 1.9219, 1.5781,\n",
       "        1.6016, 1.7578, 1.8984, 1.5391, 1.5859, 1.8984, 1.7734, 1.5000, 1.6172,\n",
       "        1.6641, 1.9531, 2.0781, 2.4688, 2.7031, 2.2344, 2.4062, 2.5156, 2.5781,\n",
       "        2.4844, 2.4219, 2.3750, 1.9766, 2.3594, 2.3125, 2.6250, 2.0938, 2.3281,\n",
       "        2.4062, 2.2500, 2.3438, 1.6875, 1.8672, 1.7500, 1.7734, 1.5938, 1.7812,\n",
       "        1.7266, 1.5703, 1.8281, 1.6406, 2.1719, 2.1719, 2.6250, 2.2812, 2.2344,\n",
       "        2.4531, 2.5312, 2.4375, 2.3594, 2.3906, 2.3594, 2.4531, 2.3750, 2.2500,\n",
       "        2.5625, 2.0000, 2.0312, 2.2969, 2.2656, 1.9219, 1.7422, 2.0312, 1.9141,\n",
       "        1.6797, 1.9844, 2.2969, 1.8359, 1.4922, 1.6328, 1.7500, 2.1562, 2.1406,\n",
       "        2.4062, 2.2969, 2.2969, 2.3438, 2.4219, 2.5781, 2.2188, 2.0938, 2.3750,\n",
       "        2.1875, 2.4375, 2.2188, 2.3594, 1.9766, 2.0781, 2.2031, 2.3438, 2.0781,\n",
       "        1.8438, 2.0312, 1.8750, 1.6250, 2.1094, 2.3125, 2.1406, 1.7188, 1.8984,\n",
       "        1.7266, 2.1562, 2.1250, 2.5781, 2.6719, 2.3281, 2.4531, 2.7031, 2.6250,\n",
       "        2.5156, 2.5938, 2.5312, 3.1094, 3.0469, 2.6875, 2.8594, 2.1875, 2.5000,\n",
       "        2.6094, 2.5938, 2.1875, 2.1094, 2.2031, 2.1719, 1.7734, 2.1562, 2.6719,\n",
       "        2.4375, 1.9219, 1.6797, 1.8438, 2.1406, 2.2188, 2.7344, 2.3281, 2.4688,\n",
       "        2.5000, 2.8594, 2.6562, 2.4844, 2.5312, 2.9688, 2.2656, 2.7812, 2.5625,\n",
       "        2.6875, 2.1406, 2.1562, 2.7500, 2.5312, 2.5000, 1.9375, 2.1094, 1.9609,\n",
       "        2.0469, 1.9297, 2.0625, 2.0156, 1.4922, 2.1875, 1.6094, 2.0469, 2.0938,\n",
       "        2.3594, 2.1562, 2.1250, 2.2188, 2.4219, 2.4844, 2.2969, 2.6250, 2.6406,\n",
       "        2.4688, 2.2188, 2.5781, 2.4844, 2.1406, 2.2344, 2.5781, 2.6719, 2.2031,\n",
       "        2.2031, 2.1406, 2.2188, 1.8984, 2.5156, 2.8594, 2.4844, 1.8047, 1.7344,\n",
       "        2.0781, 2.2812, 2.4375, 2.4844, 2.5625, 2.4531, 2.5938, 2.7812, 2.6875,\n",
       "        2.4062, 2.6094, 2.8438, 2.1875, 2.7344, 2.6094, 2.6875, 2.0469, 2.4688,\n",
       "        2.4219, 2.7344, 2.3438, 2.0625, 2.1406, 2.0781, 1.8125, 2.5781, 2.5312,\n",
       "        2.4531, 2.0312, 2.1719, 1.6875, 2.0781, 2.2656, 2.4844, 2.2500, 2.4062,\n",
       "        2.5156, 2.7344, 2.6719, 2.3281, 2.5781, 2.4062, 2.7969, 2.8906, 2.5000,\n",
       "        2.7344, 2.1250, 2.3125, 2.6562, 2.6562, 2.2031, 2.0156, 2.1094, 2.1719,\n",
       "        1.7344, 2.2188, 2.6406, 2.4375, 1.9375, 1.8516, 1.7266, 1.8828, 2.1250,\n",
       "        2.2344, 2.0469, 1.9766, 2.1875, 2.4219, 2.4219, 2.1719, 2.1875, 2.5625,\n",
       "        2.1875, 2.4062, 2.1562, 2.3438, 1.9141, 1.8516, 2.2812, 2.2812, 2.1250,\n",
       "        1.7656, 1.9375, 1.7812, 1.7969, 1.7578, 1.8984, 1.8281, 1.4609, 2.5156,\n",
       "        1.5391, 1.8438, 2.0781, 2.2188, 2.1875, 2.0781, 2.2656, 2.4375, 2.3594,\n",
       "        2.1562, 2.3438, 2.1562, 2.8281, 2.9844, 2.4219, 2.5000, 1.9453, 2.0312,\n",
       "        2.3906, 2.5156, 2.2344, 1.9609, 2.1406, 2.0938, 1.9062, 2.4062, 2.6719,\n",
       "        2.4062, 1.7656, 1.9375, 1.6719, 1.8672, 2.0625, 2.2969, 2.0469, 2.2188,\n",
       "        2.4219, 2.5938, 2.4531, 2.1406, 2.3281, 2.7344, 2.1250, 2.8594, 2.4531,\n",
       "        2.5156, 1.9531, 2.3438, 2.3438, 2.5938, 2.1250, 1.9375, 2.1562, 1.9219,\n",
       "        1.8203, 2.4062, 2.3750, 2.3594, 1.9219, 2.3906, 1.5391, 1.8359, 1.9609,\n",
       "        2.2344, 1.9688, 1.9062, 1.9922, 2.2656, 2.3750, 2.1719, 2.4531, 2.4688,\n",
       "        2.2812, 2.2188, 2.5000, 2.5000, 2.0469, 2.4844, 2.5312, 2.4531, 1.9453,\n",
       "        1.9531, 2.2188, 2.1875, 1.7812, 2.3125, 2.7188, 2.3906, 1.6484, 2.1719,\n",
       "        1.5625, 1.9453, 2.0625, 2.2344, 2.4062, 2.1719, 2.3906, 2.4375, 2.4688,\n",
       "        2.0938, 2.3594, 2.7656, 2.0781, 2.6875, 2.4219, 2.5000, 1.8672, 1.8906,\n",
       "        2.4375, 2.3594, 2.4531, 1.8672, 2.0938, 1.8906, 1.8906, 1.8828, 2.0312,\n",
       "        2.0781, 1.5625, 2.5156, 1.4375, 1.6641, 1.9766, 2.2969, 1.9531, 2.0312,\n",
       "        2.2344, 2.3906, 2.3750, 2.1875, 2.4219, 2.2969, 2.7188, 2.8594, 2.3750,\n",
       "        2.4219, 1.9062, 1.9453, 2.3750, 2.4219, 2.2500, 1.9062, 2.1094, 2.0469,\n",
       "        1.9375, 2.4375, 2.6406, 2.3906, 1.8594, 2.2188, 1.5156, 1.7656, 1.8750,\n",
       "        2.0156, 1.8516, 1.7812, 1.9062, 2.1250, 2.2812, 2.1094, 2.0469, 2.3281,\n",
       "        2.1562, 2.3125, 2.1562, 2.2656, 1.8672, 2.1250, 1.9766, 2.1875, 2.0469,\n",
       "        1.7891, 1.9766, 1.8359, 1.7266, 2.4375, 2.3906, 2.2500, 1.8516, 2.6875,\n",
       "        1.5625, 1.8125, 1.9922, 2.1250, 2.1406, 1.9453, 2.2344, 2.3906, 2.3750,\n",
       "        2.1250, 2.3125, 2.0938, 2.7500, 2.9844, 2.4688, 2.5781, 1.9375, 2.1719,\n",
       "        2.5000, 2.5469, 2.1719, 1.9609, 2.2812, 2.2031, 1.8750, 2.2812, 2.5625,\n",
       "        2.4531, 1.8828, 1.8438, 1.5312, 1.7812, 2.0312, 2.2031, 2.0625, 1.9844,\n",
       "        2.3438, 2.4844, 2.5156, 2.1719, 2.3750, 2.8594, 2.1562, 2.9375, 2.5312,\n",
       "        2.5312, 1.9219, 1.8281, 2.5625, 2.5312, 2.3750, 1.8594, 2.1875, 1.9141,\n",
       "        1.9688, 1.8984, 1.9609, 2.0469, 1.4219, 2.7656, 1.5078, 1.6562, 1.8516,\n",
       "        2.0469, 1.9062, 1.8281, 1.8672, 2.0625, 2.2812, 2.0781, 2.3906, 2.3906,\n",
       "        2.2031, 2.2031, 2.3906, 2.3906, 1.8672, 1.8359, 2.4844, 2.6094, 2.0781,\n",
       "        2.0312, 2.2656, 2.1719, 2.0469, 2.6094, 2.7188, 2.3906, 1.7266, 2.6094,\n",
       "        1.5469, 1.7422, 1.9375, 2.0469, 2.2500, 2.0938, 2.2812, 2.4844, 2.4844,\n",
       "        2.1250, 2.4062, 2.8125, 2.1094, 2.7969, 2.4688, 2.5000, 1.8750, 2.2344,\n",
       "        2.2188, 2.4375, 2.3281, 1.9062, 2.1562, 1.8984, 1.7891, 2.5625, 2.4062,\n",
       "        2.3906, 1.8125, 2.7969, 1.5391, 1.8203, 1.9844, 2.1406, 1.9453, 1.9844,\n",
       "        2.4688, 2.5312, 2.6406, 2.2500, 2.6094, 2.5469, 2.9375, 3.0312, 2.5625,\n",
       "        2.7656, 2.0625, 2.3125, 2.6406, 2.6719, 2.2344, 2.0000, 2.4062, 2.2031,\n",
       "        2.0312, 2.3750, 2.6875, 2.3906, 1.8281, 2.3438, 1.5312, 1.7500, 1.8828,\n",
       "        1.9375, 1.9141, 1.7734, 1.9531, 2.1875, 2.3906, 2.1406, 2.2031, 2.4219,\n",
       "        2.0625, 2.4062, 2.1094, 2.3438, 1.7578, 1.6719, 2.3750, 2.2500, 2.3125,\n",
       "        1.8047, 2.0000, 1.7891, 1.8125, 1.8203, 1.9062, 1.8047, 1.3281, 3.0469,\n",
       "        1.2031, 1.5312, 1.7031, 1.7422, 2.2188, 2.2500, 2.0781, 1.9766, 2.1875,\n",
       "        2.6250, 2.6406, 2.5625, 2.5781, 2.5781, 2.5156, 2.5156, 2.1094, 2.0000,\n",
       "        2.5000, 2.5156, 2.3750, 1.8359, 1.9766, 2.0625, 2.1875, 2.2500, 2.2656,\n",
       "        2.0469, 1.5938, 1.8047, 1.2031, 1.7266, 1.6406, 1.5234, 1.4844, 1.4375,\n",
       "        1.4688, 1.5547, 1.5312, 1.3203, 1.2109, 1.1875, 1.2578, 1.2266, 1.1172,\n",
       "        1.0469, 1.0781, 1.2031, 1.4219, 1.4375, 1.3047, 1.0859, 1.2422, 1.1172,\n",
       "        1.3125, 1.4844, 1.3281, 1.2422, 1.8984], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(logits1 - logits2),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ad532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3451e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609d3c68c8084415b615279d7ddd0e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, Gemma3ForConditionalGeneration\n",
    "\n",
    "model = Gemma3ForConditionalGeneration.from_pretrained(\n",
    "    \"google/gemma-3-4b-it\",\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    # device_map=\"auto\",\n",
    "    # attn_implementation=\"sdpa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebb28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randint(0, 1000, (1, 256))#.to(\"cuda\")\n",
    "start_idx = 128\n",
    "end_idx = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b69d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n",
    "with torch.no_grad():\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        outputs_full = model(inputs)\n",
    "        logits1 = outputs_full.logits[0, start_idx: end_idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05f92f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import HybridCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9ab19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_values = HybridCache(model.config.text_config, 1, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8c695",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 256 is out of bounds for dimension 1 with size 256",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Iterate through the continuation tokens\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end_idx \u001b[38;5;241m-\u001b[39m start_idx):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Prepare input for the next iteration: only the current continuation token\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     current_token_id_tensor \u001b[38;5;241m=\u001b[39m inputs[:, start_idx \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Model call with the single next token and past_key_values\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16):\n",
      "\u001b[0;31mIndexError\u001b[0m: index 256 is out of bounds for dimension 1 with size 256"
     ]
    }
   ],
   "source": [
    "logits2 = []\n",
    "with torch.no_grad():\n",
    "    # Initial pass with the input prompt\n",
    "    with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        outputs_kv_init = model(inputs[:,:start_idx + 1], use_cache=True, past_key_values=past_key_values)\n",
    "        logits2.append(outputs_kv_init.logits[0, -1, :])\n",
    "        # Store the KV cache from initial pass\n",
    "        past_key_values = outputs_kv_init.past_key_values\n",
    "\n",
    "    # Iterate through the continuation tokens\n",
    "    for i in range(end_idx - start_idx - 1):\n",
    "        # Prepare input for the next iteration: only the current continuation token\n",
    "        current_token_id_tensor = inputs[:, start_idx + i + 1].unsqueeze(1)\n",
    "\n",
    "        # Model call with the single next token and past_key_values\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            outputs_kv_step = model(input_ids=current_token_id_tensor, \n",
    "                                   past_key_values=past_key_values, \n",
    "                                   use_cache=True)\n",
    "            # Store the logits from this step - CORRECTION HERE\n",
    "            logits2.append(outputs_kv_step.logits[0, -1, :])\n",
    "            # Update KV cache with new values\n",
    "            past_key_values = outputs_kv_step.past_key_values\n",
    "logits2 = torch.stack(logits2, dim=0)\n",
    "logits2.shape, logits1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0c2842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 262208]), torch.Size([128, 262208]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits2 = torch.stack(logits2, dim=0)\n",
    "logits2.shape, logits1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea6b216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.5761e-06, 7.2332e-06, 7.8308e-06, 8.9197e-06, 7.5235e-06, 7.1803e-06,\n",
       "        9.2514e-06, 1.0456e-05, 9.3818e-06, 1.2672e-05, 9.0390e-06, 8.1634e-06,\n",
       "        7.5472e-06, 1.1036e-05, 1.1434e-05, 1.0017e-05, 9.7087e-06, 1.2099e-05,\n",
       "        1.3566e-05, 1.0992e-05, 8.9328e-06, 8.0241e-06, 7.5371e-06, 8.4412e-06,\n",
       "        1.1368e-05, 7.4331e-06, 8.1296e-06, 8.6147e-06, 8.4934e-06, 1.0547e-05,\n",
       "        9.2572e-06, 7.8645e-06, 9.2196e-06, 1.1559e-05, 9.1299e-06, 1.1141e-05,\n",
       "        9.9925e-06, 1.1491e-05, 8.4543e-06, 9.1530e-06, 8.3192e-06, 8.1446e-06,\n",
       "        9.0655e-06, 1.0497e-05, 8.2049e-06, 1.0780e-05, 7.5738e-06, 8.0629e-06,\n",
       "        6.8507e-06, 1.0084e-05, 9.1416e-06, 8.0334e-06, 8.4851e-06, 1.0729e-05,\n",
       "        1.3607e-05, 7.8625e-06, 7.1217e-06, 7.0614e-06, 7.1365e-06, 9.5032e-06,\n",
       "        1.0092e-05, 7.0158e-06, 8.9976e-06, 9.3340e-06, 1.2156e-05, 8.5299e-06,\n",
       "        9.6471e-06, 1.3323e-05, 1.4118e-05, 1.1182e-05, 7.2470e-06, 9.4420e-06,\n",
       "        1.4857e-05, 1.0573e-05, 6.9856e-06, 6.7008e-06, 8.0400e-06, 6.8249e-06,\n",
       "        6.3196e-06, 6.5911e-06, 7.4116e-06, 6.7315e-06, 7.1983e-06, 6.5463e-06,\n",
       "        8.3482e-06, 8.0930e-06, 5.2618e-06, 9.3029e-06, 7.1126e-06, 8.6791e-06,\n",
       "        9.0481e-06, 8.4542e-06, 6.8355e-06, 8.4746e-06, 7.4499e-06, 8.2346e-06,\n",
       "        7.0119e-06, 6.8156e-06, 7.0467e-06, 8.4187e-06, 8.6727e-06, 9.1642e-06,\n",
       "        7.2884e-06, 7.7947e-06, 6.7549e-06, 8.4489e-06, 7.1558e-06, 7.1298e-06,\n",
       "        6.3564e-06, 4.9521e-06, 5.7325e-06, 6.7724e-06, 6.3755e-06, 5.5515e-06,\n",
       "        4.1408e-06, 1.1932e-05, 4.5188e-06, 4.8639e-06, 1.4389e-05, 1.1451e-05,\n",
       "        5.5890e-06, 4.4352e-06, 4.8694e-06, 5.0882e-06, 4.2243e-06, 4.2550e-06,\n",
       "        4.4754e-06, 4.3902e-06])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.abs(logits1 - logits2),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb5ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
